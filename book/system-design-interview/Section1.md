# 1장 사용자 수에 따른 규모 확장성

## 단일 서버
> 웹, 앱, 데이터베이스, 캐시 등이 전부 서버 한 대에서 실행된다.

![image](https://github.com/hoa0217/study-repo/assets/48192141/61e74f6b-e0cd-489b-ba41-7a426b00fffe)

1. 사용자는 도메인 이름(api.mysite.com)을 이용하여 웹사이트에 접속한다.
2. DNS 조회 결과로 IP 주소가 반환된다.
3. 해당 IP 주소로 HTTP 요청이 전달된다.
4. 요청을 받은 웹서버는 HTML 페이지 또는 JSON 형태의 응답을 반환한다.

### 요청의 두가지 종류의 단말
- 웹 어플리케이션: 비즈니스 로직, 데이터 저장 등을 처리하귀 위해 서버 구현용 언어(자바, 파이썬 등)를 사용하고, 표현용으로 클라이언트 구현용 언어(HTML, JS 등)를 사용한다.
- 모바일 앱: 모바일 앱과 웹 서버 간 통신을 위해서는 HTTP 프로토콜을 이용한다. 응답 데이터 포맷은 보통 JSON을 사용한다.

## 데이터베이스

![image](https://github.com/hoa0217/study-repo/assets/48192141/38362b2f-a20b-4823-bfe8-ed41f7bf7ef7)

- 사용자가 늘면 서버하나로는 충분하지 않아 여러 서버를 두어야한다.
- 웹/모바일 트래픽 처리 서버와 DB 서버를 분리하면 각각을 독립적으로 확장해 나갈 수 있다.

### 어떤 데이터베이스를 사용할 것인가?
전통적인 관계형 데이터베이스와 비-관계형 데이터베이스사이에서 고를 수 있다.

관계형 데이터베이스(RDBMS): 자료를 테이블과 열, 컬럼으로 표현한다.
- SQL을 사용하면 여러 테이블에 있는 데이터를 관계에 따라 조인할 수 있다.
- ex) MySQL, Oracle, PostgreSQL 등

비관계형 데이터베이스(NoSQL): 키-값 저장소, 그래프 저장소, 칼럼 저장소, 문자 저장소로 나뉜다.
- 일반적인 조인 연산은 지원하지 않는다.
- ex) DouchDB, Neo4j, Cassandra, HBase, Amazon DynamoDB 등

대부분은 관계형을 사용하지만, 아래와 같은 경우 비-관계형이 바람직할 수 있다.
- 아주 낮은 응답 지연시간이 요구됨
- 다루는 데이터가 비정형이라 관계형 데이터가 아님
- 데이터(JSON, YAML, XML 등)를 직렬화하거나 역직렬화할 수 있기만 하면 됨
- 아주 많은 양의 데이터를 저장할 필요가 있음

## 수직적 규모 확장 vs 수평적 규모 확장
- 스케일업(scale up): 수직적 규모 확장 프로세스. 서버에 고사양 자원 추가.
- 스케일 아웃(scale out): 수평적 규모 확장 프로세스. 더 많은 서버 추가.

서버로 유입되는 트래픽양이 적을 때는 수직적 규모 확장이 좋은 선택이며, 가장 큰 장점은 단순함.

하지만 아래와 같은 단점으로 **대규모 애플리케이션에선 수평적 규모 확장이 적절하다.**
- 수직적 규모 확장에는 한계가 있다. 한 대의 서버에 CPU나 메모리를 무한대로 증설할 수 없다.
- 수직적 규모 확장법은 장애에 대한 자동복구방안이나 다중화방안을 제시하지 않는다.

> 앞에서 본 설계는 WAS로 바로 연결되며, 서버가 다운되면 사용자는 접속할 수 없다.   
> 또한 너무 많은 사용자가 접속하여 서버가 한계 상황에 도달하면 응답속도가 느려지거나 서버 접속이 불가능하다.
> 이런 문제를 해결하는데는 부하 분산기 또는 **로드밸런서**를 도입하는 것이 최선이다.

### 로드밸런서

![image](https://github.com/hoa0217/study-repo/assets/48192141/6fa7dc31-c5c7-4e75-88b4-7200a9d069df)

- 로드밸런서: 부하 분산 집합(load balancing set)에 속한 웹 서버들에게 트래픽 부하를 고르게 분산하는 역할을 한다.
- 사용자는 로드밸런서의 공개IP로 접속하게 되며, WAS는 클라이언트 접속을 직접 처리하지 않고 보안을 위해 사설IP로 로드밸런서와 통신한다.

#### 만약 서버 하나가 다운되면?
- 서버1이 다운되면 모든 트래픽은 서버2로 전송된다. 따라서 웹 사이트 전체가 다운되는 일이 방지된다. 부하를 나누기 위해 새로운 서버를 추가할 수 도 있다.
- 웹사이트로 유입되는 트래픽이 가파르게 증가하면 두 대의 서버로 트래픽을 감당할 수 없는 시점이 오며 이때 웹 서버 계층에 더 많은 서버를 추가하면된다. 그러면 로드밸런서가 자동적으로 트래픽을 분산하기 시작할 것이다.

### 데이터베이스 다중화
> 많은 데이터베이스 관리 시스템이 다중화를 지원한다. 보통은 서버 사이에 주(master)-부(slave) 관계를 설정하고 데이터 원본은 주서버에 사본은 부 서버에 저장하는 방식이다.

![image](https://github.com/hoa0217/study-repo/assets/48192141/709c21ad-0ffe-476a-be24-a319e9a8f829)

- 쓰기 연산(write operation)은 master에서만 지원한다. ➡️ insert, delete, update 
- slave는 master로부터 사본을 전달받아 읽기 연산(read operation)만을 지원한다.
- 대부분의 애플리케이션은 읽기 연산이 쓰기 연산보다 훨씬 높으므로 통상 slave 수가 master보다 많다.

다중화를 하면 아래와 같은 장점이 있다.
- 더 나은 성능: 모든 쓰기 연산은 master 서버로 읽기 연산은 slave 서버로 분산된다.
  - 병렬로 처리될 수 있는 질의(query)의 수가 늘어나므로 성능이 좋아진다.
- 안정성(reliability) : 자연 재해 등의 이유로 DB 서버 일부가 파괴되어도 데이터는 보존될 것.
  - 데이터를 지역적으로 떨어진 여러장소에 다중화 시켜놓을 수 있기 때문.
- 가용성(availability) : 하나의 DB서버에 장애가 발생하더라도 다른 서버에있는 데이터를 가져와 계속 서비스 할 수 있다.
  - 데이터를 여러 지역에 복제할 수 있기 때문.

#### 만약 DB 서버 가운데 하나가 다운되면? 
slave가 다운된 경우
- slave가 한대인 경우 읽기 연산은 한시적으로 master로 전달된다. 또한 즉시 새로운 slave가 장애 서버를 대체할것
- slave가 여러대인 경우 읽기 연산은 나머지 slave로 분산될 것이며, 새로운 slave가 장애 서버를 대체할 것

master가 다운된 경우
- slave가 한대인 경우 일시적으로 master가 되며, 한시적으로 모든 연산은 master로 전달된다. 또한 즉시 새로운 slave가 장애서버를 대체한다.
> 프로덕션 환경에서 벌어지는 일은 사실 이보다 복잡하다. slave에 보관된 데이터가 최신 상태가 아닐 가능성이 있기 때문. 없는 데이터는 복구 스크립트를 돌려 추가해야한다.
> 다중 마스터나 원형 다중화 방식을 도입하면 이런 상황을 대처하는데 도움이 될 수 있지만 구성이 복잡하다.

### 로드밸런서와 DB다중화를 고려한 설계안

![image](https://github.com/hoa0217/study-repo/assets/48192141/58f69529-a704-4190-bac2-fb757598056c)

1. 사용자는 DNS로부터 로드밸런서의 공개 IP 주소를 받는다.
2. 사용자는 해당 IP 주소를 사용해 로드밸런서에 접속한다.
3. HTTP 요청은 서버 1이나 서버 2로 전달된다.
4. 웹 서버는 사용자의 데이터를 slave DB에서 읽는다.
5. 웹 서버는 데이터 변경 연산은 master DB로 전달한다. (추가, 삭제, 갱신)

## 캐시
> 응답시간을 개선하기 위해선 캐시를 붙이고 정적콘텐츠를 CDN으로 옮기면 개선할 수 있다.

캐시: 값비싼 연산 결과 또는 자주 참조되는 데이터를 메모리 안에 두고, 뒤이은 요청보다 빨리 처리될 수 있도록 하는 저장소
- 웹 페이지를 새로고침 할 때마다 표시할 데이터를 가져오기 위해 1번 이상 DB 호출이 발생한다.
- 애플리케이션의 성능은 DB를 얼마나 자주 호출하느냐에 크게 좌우되며 캐시는 이런 문제를 완화할 수 있다.

### 캐시 계층

캐시 계층을 두면 성능이 개선될 뿐 아니라 DB의 부하도 줄일 수 있고, 캐시 계층의 규모를 독립적으로 확장시키는 것도 가능하다.

![image](https://github.com/hoa0217/study-repo/assets/48192141/8979b538-1455-4e47-882c-17b15748b71a)

> 위 그림과 같은 캐시 전략을 **주도형 캐시 전략**이라고 부른다.

### 캐시 사용 시 유의할점
캐시는 어떤 상황에 바람직한가? 
- 캐시는 데이터 갱신은 자주 일어나지 않지만 참조는 빈번하게 일어난다면 고려해볼 만하다.

어떤 데이터를 캐시에 두어야 하는가?
- 캐시는 데이터를 휘발성 메모리에 두므로, 영속적으로 보관할 데이터는 바람직하지 않다.
- 중요한 데이터는 지속적 저장소(persistent data store)에 두어야한다.

캐시에 보관된 데이터는 어떻게 만료되는가?
- 이에 대한 정책을 마련해 두는 것은 좋은 습관이다.
- 만료된 데이터는 캐시에서 삭제되어야 하며 만료 정책이 없으면 데이터는 캐시에 계속 남게된다.
- 만료기한이 너무 짧으면 DB를 너무 자주 읽게 될것이고 너무 길면 원본과 차이가 날 가능성이 높아진다.

일관성은 어떻게 유지되는가?
- 일관성은 데이터 저장소의 원본과 캐시 내의 사본이 같은 여부다.
- 원본을 갱신할 때 캐시를 갱신하는 연선이 단일 트랜잭션으로 처리되지 않는 경우 일관성은 깨질 수 있다.
- 시스템을 확장해 나가는 경우 캐시와 저장소 사이의 일관성을 유지하는 것은 어려운 문제가 된다.

장애에는 어떻게 대처할 것인가?
- 캐시 서버를 한대만 두는 경우 해당 서버는 단일 장애 지점(Single Point of Failure, SPOF)이 되어버릴 가능성이 있다.
  - SPOF: 어떤 특정지점에서의 장애가 전체 시스템의 동작을 중단시켜버릴 수 있는경우
- SPOF를 피하려면 여러지역에 걸쳐 캐시 서버를 분산시켜야 한다.

캐시 메모리는 얼마나 크게 잡을 것인가?
- 캐시 메모리가 너무 작으면, 액세스 패턴에 따라 데이터가 자주 밀려나버려(eviction) 캐시의 성능이 떨어진다.
- 해결 방법은 캐시 메모리를 과할당(overprovision)하는 것. 캐시에 보관될 데이터가 갑자기 늘어다도 문제를 방지할 수 있음.

데이터 방출(eviction)정책은 무엇인가?
- 캐시가 꽉 차버린 후 데이터를 더 넣어야할 경우 기존 데이터를 내보내야한다.
- 가장 널리 쓰이는 것이 LRU(Least Recently Used, 마지막으로 사용된 시점이 오래된 데이터 방출)이다.
- 다른 정책으로 LFU(Least Frequently Used, 사용된 빈도가 가장 낮은 데이터 방출), FIFO(First In First Out, 가장 먼저 들어온 데이터 방출)가 존재한다.

## 콘텐츠 전송 네트워크(CDN)

![image](https://github.com/f-lab-edu/modoospace/assets/48192141/b78d9282-96dd-4b6c-95fd-f0c61c2582f6)

- CDN은 정적 콘텐츠를 전송하는데 쓰이는, 지리적으로 분산된 서버의 네트워크이다.
- 이미지, 비디오, CSS, JS등을 캐시할 수 있다.
- 사용자가 웹사이트를 방문하면 사용자에게 가장 가까운 CDN서버가 정적 콘텐츠를 전달한다.
- CDN 서버가 멀면 멀수록 웹사이트는 천천히 로드된다.

> 동적 콘텐츠 캐싱은 요청경로(request path), 질의 문자열(query string), 쿠키(cookie), 요청헤더(request header)등 정보에 기반하여 HTML 페이지를 캐시한다.

### CDN 동작

![image](https://github.com/f-lab-edu/modoospace/assets/48192141/3ea1dacf-e5ab-4c6d-8624-8cedfae85067)
1. 사용자 A가 이미지 URL을 사용해 image.png에 접근한다. 
   - URL의 도메인은 CDN 서비스 사업자가 제공한것.
2. CDN 서버의 캐시에 해당 이미지가 없는 경우, 원본 서버에 요청하여 파일을 가져온다.
   - 원본서버는 웹서버일 수도 S3같은 온라인 저장소일 수 있다.
3. 원본 서버가 파일을 CDN 서버에 반환한다. 응답의 HTTP 헤더에는 TTL이 들어있다.
4. CDN 서버는 파일을 캐시하고 사용자 A에게 반환한다. 이미지는 TTL에 명시된 시간이 끝날 때까지 캐시된다.
5. 사용자 B가 같은 이미지에 대한 요청을 CDN 서버에 전송한다.
6. 만료되지 않은 이미지에 대한 요청은 캐시를 통해 처리된다.

### CDN 사용시 고려해야할 사항
- 비용: 보통 제 3자에 의해 운영되며, 전송양에 따라 요금을 내게 된다. 자주 사용되지 않는 콘텐츠를 캐싱하는 것은 이득이 크지않으므로 빼는 것을 고려.
- 적절한 만료 시한 설정: 시의성이 중요한 콘텐츠의 경우 만료 시점을 잘 정해야한다. 너무 길면 컨텐츠의 신선도가 떨어지고 너무 짧으면 원본 서버에 빈번히 접속하게 된다.
- CDN 장애 대처 방안: CDN이 일시적으로 응답하지 않을 경우, 어플리케이션은 해당 문제를 감지하여 원본 서버로부터 직접 콘텐츠를 가져오도록 구성하는 것이 필요할 수도 있다.
- 콘텐츠 무효화: 아직 만료되지 않은 콘텐츠여도 아래 방법을 쓰면 CDN에서 제거할 수 있다.
  - CDN 서비스 사업자가 제공하는 API를 이용한 무효화
  - 콘텐츠의 다른 버전을 서비스하도록 오브젝트 버저닝 이용.

### CDN과 캐시가 추가된 설계

![image](https://github.com/f-lab-edu/modoospace/assets/48192141/cfff5c81-767c-480f-a763-0fc3fb9e5383)

1. 정적 콘텐츠(JS, CSS, 이미지 등) 더 이상 웹 서버를 통해 서비스하지 않으며, CDN을 통해 제공하여 더 나은 성능을 보장한다.
2. 캐시가 데이터베이스 부하를 줄여준다.

## 무상태 웹계층

- 웹을 수평적으로 확장하기 위해선, 상태 정보(사용자 세션)을 웹 계층에서 제거해야 한다.
- 바람직한 전략은 상태 정보를 DB(RDBS, NoSQL)에 저장하여 필요할 때 가져오도록 하는 것이다.
- 이렇게 구성된 웹계층을 **무상태 웹계층**이라 부른다.

### 상태 정보 의존적인 아키텍처

![image](https://github.com/f-lab-edu/modoospace/assets/48192141/0a56d933-63a8-43f8-8f99-0e9b9df312d1)

- 상태 정보를 보관하는 서버는 클라이언트 정보(상태)를 유지하여 요청들 사이에 공유되도록 한다.
- 사용자 A의 정보가 만약 서버1에 저장되어있을 경우 서버2로 요청이 전송되면 인증은 실패한다.
- 즉, 같은 클라이언트로부터 요청은 항상 같은 서버로 전송되어야한다.
- 이를 위해 대부분의 로드밸런서는 고정 세션(sticky session)기능을 제공하는데, 이는 로드밸런서에 부담을 준다.
- 게다가 로드밸런서 뒷단에 서버를 추가하거나 제거하기도 까다로워진다. 장애 처리 또한 복잡해진다.

### 무상태 아키텍처

![image](https://github.com/f-lab-edu/modoospace/assets/48192141/e9d2b788-4225-4e16-8967-84c8a13d8332)

- 사용자의 요청은 어떤 웹서버로도 전달될 수 있다.
- 웹서버는 상태 정보가 필요한 경우 공유 저장소로부터 데이터를 가져온다.
- 상태 정보는 웹서버로부터 물리적으로 분리되어있다.
- 이런 구조는 단순하고 안정적이며 규모확장이 쉽다. 자동규모확장(autoscaling) 또한 가능하다.
- 공유 저장소는 RDBS일수도 NoSQL일수도 Memcached/Redis 같은 캐시시스템일 수도 있다.

> 만약 웹사이트가 급성장하여 가용성을 높이고 전세계에서 쾌적하게 사용할 수 있도록 하기 위해서는 여러 데이터 센터를 지원하는것이 필수다.

## 데이터 센터

![image](https://github.com/f-lab-edu/modoospace/assets/48192141/4ab0476d-c2fb-449d-bbec-908b7c0ff476)

- 두 개의 데이터 센터를 이용한다면, 장애가 없는 상황에서 사용자는 가장 가까운 데이터 센터로 안내된다.
- 이 절차는 지리적 라우팅(geo-routing, geoDNS-routing)라 부르며, geoDNS는 사용자 위치에 따라 어떤 IP로 변환할지 결정한다.

### 기술적 난제
- 트래픽 우회: 올바른 데이터 센터로 트래픽을 보내는 효과적인 방법을 찾아야 한다. geoDNS가 해당 역할을 한다.
- 데이터 동기화: 데이터 센터마다 별도의 DB를 사용하고 있는 상황이라면, 장애가 자동으로 복구되어 트래픽이 다른 DB로 우회되면 찾는 데이터가 없을 수도 있다.   
이런 상황을 막는 전략은 데이터를 여러 데이터센터에 걸쳐 다중화하는 것이다.
- 테스트와 배포: 여러 위치에서 애플리케이션을 테스트 해보고, 자동화 배포가 모든 데이터 센터에 동일하게 설치되도록 하는 것이 중요합니다.

> 시스템을 더 큰 규모로 확장하기 위해서는 컴포넌트를 분리하여 독립적으로 확장될 수 있어야한다. 실제 분산 시스템에서 이 문제를 풀기위해 메시지 큐를 사용한다. 

## 메시지 큐

이미지 참고 : [[가상 면접 사례로 배우는 대규모 시스템 설계 기초] 1장 사용자 수에 따른 규모 확장성
](https://velog.io/@haron/%EA%B0%80%EC%83%81-%EB%A9%B4%EC%A0%91-%EC%82%AC%EB%A1%80%EB%A1%9C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%EB%8C%80%EA%B7%9C%EB%AA%A8-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%84%A4%EA%B3%84-%EA%B8%B0%EC%B4%88-1%EC%9E%A5-%EC%82%AC%EC%9A%A9%EC%9E%90-%EC%88%98%EC%97%90-%EB%94%B0%EB%A5%B8-%EA%B7%9C%EB%AA%A8-%ED%99%95%EC%9E%A5%EC%84%B1)